

===== FILE: Agent.py =====

import random 
import numpy as np

# --- Neuron and Synapse Classes ---
class Neuron:
    def __init__(self, name):
        self.name = name
        self.state = 0.0
        self.threshold_pos = random.uniform(0.05, 0.5)
        self.threshold_neg = random.uniform(-0.5, -0.05)
        self.fired = False
        

    def reset(self):
        self.state = 0.0
        self.fired = False

    def receive(self, value):
        self.state += value
        self.state = max(-1.0, min(1.0, self.state))

    def update(self):
        if self.state >= self.threshold_pos:
            self.fired = True
            return 'excite'
        elif self.state <= self.threshold_neg:
            self.fired = True
            return 'inhibit'
        else:
            self.fired = False
            return None

class Synapse:
    def __init__(self, pre, post, weight):
        self.pre = pre
        self.post = post
        self.weight = weight
        self.learning_rate = 0.1

    def propagate(self):
        if self.pre.fired:
            signal = 1.0 if self.pre.state > 0 else -1.0
            self.post.receive(signal * self.weight)

    def update_weight(self, reward):
        if self.pre.fired and self.post.fired:
            delta = self.learning_rate * reward # Scale learning rate by reward magnitude
            self.weight = max(min(self.weight + delta, 1.0), -1.0)


class Agent:
    def __init__(self, name, neuron_count):
        self.name = name
        self.neurons = [Neuron(f"{name}_n{i}") for i in range(neuron_count)]
        self.synapses = []
        self.energy = 100.0
        self.position = (0, 0)

        self.initialize_synapses()

        if neuron_count < 3:
            raise ValueError("Agent must have at least 2 neurons for output actions.")
        self.output_neurons = self.neurons[-4:]

    def initialize_synapses(self):
        self.synapses = []
        for _ in range(len(self.neurons) * 10):
            pre, post = random.sample(self.neurons, 2) if len(self.neurons) >= 2 else (self.neurons[0], self.neurons[0])
            weight = random.uniform(-1, 1)
            self.synapses.append(Synapse(pre, post, weight))

    def reset(self):
        for n in self.neurons:
            n.reset()

    def step(self, think=1):
        for round in range(think):
            for syn in self.synapses:
                syn.propagate()
            for n in self.neurons:
                n.update()

    def learn(self, reward_value): # Renamed 'won' to 'reward_value' for clarity
        for syn in self.synapses:
            syn.update_weight(reward_value) # Pass the numerical reward


    def receive_inputs(self, inputs):
        for i, value in enumerate(inputs):
            if i < len(self.neurons):
                self.neurons[i].receive(value)

    def decide_action(self):
        output_mean = np.mean([n.state for n in self.output_neurons])

        return output_mean

===== FILE: agent_eval.py =====

from data_generation import normalize_window

def evaluate_agent(agent, prices, initial_cash=1000):
    cash = initial_cash
    crypto = 0.0
    portfolio_history = []

    for i in range(3, len(prices)):
        price = prices[i]
        window = prices[i-3:i+1]
        inputs = normalize_window(window)

        agent.reset()
        agent.receive_inputs(inputs)
        agent.step(think=2)
        output = agent.decide_action()

        # Clamp output to [-1, 1]
        output = max(-1.0, min(1.0, output))

        # Calculate portfolio value BEFORE action
        portfolio_value = cash + crypto * price
        target_allocation = (output + 1.0) / 2.0  # [-1,1] → [0,1]
        target_crypto_value = target_allocation * portfolio_value
        current_crypto_value = crypto * price
        delta = target_crypto_value - current_crypto_value

        if delta > 0:
            # Buy
            max_affordable = cash
            amount_to_buy = min(delta, max_affordable) / price
            crypto += amount_to_buy
            cash -= amount_to_buy * price
        else:
            # Sell
            amount_to_sell = min(-delta / price, crypto)
            crypto -= amount_to_sell
            cash += amount_to_sell * price

        # Save new portfolio value
        portfolio_history.append(cash + crypto * price)

    return portfolio_history[-1], portfolio_history


===== FILE: data_generation.py =====

import numpy as np
import matplotlib.pyplot as plt

def generate_synthetic_data(length=100):
    mean = 0
    std = 1
    prices = [100.0]
    for _ in range(length - 1):
        change = np.random.normal(mean, std)  # Small random walk
        mean += np.random.uniform(-.01, .01)
        std += abs(np.random.normal(0, 1))
        prices.append(max(0.01, prices[-1] + change))
    return np.array(prices)

def normalize_window(window):
    diffs = np.diff(window)
    return diffs / (np.std(diffs) + 1e-6)


===== FILE: evo_loop.py =====

from Agent import Agent 
import random
import numpy as np
import matplotlib.pyplot as plt 
import pickle

from data_generation import generate_synthetic_data 
from agent_eval import evaluate_agent
from mutations import mutate_agent

def create_population(n_agents, n_neurons):
    return [Agent(f"agent_{i}", n_neurons) for i in range(n_agents)]


def evolve(pop_size=20, generations=30, base_neurons=10, mutation_rate=0.1, mutation_strength=0.2):
    population = [Agent(f"agent_{i}", base_neurons) for i in range(pop_size)]
    data = generate_synthetic_data(length=200)

    for gen in range(generations):
        scores = [(agent, evaluate_agent(agent, data)) for agent in population]
        scores.sort(key=lambda x: x[1], reverse=True)

        best_score = scores[0][1][0] if isinstance(scores[0][1], tuple) else scores[0][1]
        avg_score = np.mean([s[1][0] if isinstance(s[1], tuple) else s[1] for s in scores])
        print(f"Gen {gen} - Best: {best_score:.2f} - Avg: {avg_score:.2f}")


        survivors = [s[0] for s in scores[:pop_size // 2]]
        children = [mutate_agent(random.choice(survivors), mutation_rate, mutation_strength)
                    for _ in range(pop_size - len(survivors))]

        population = survivors + children

    # --- Save population ---
    with open("final_population.pkl", "wb") as f:
        pickle.dump(population, f)

    # --- Evaluate and Plot Best Agent ---
    best_agent = population[0]
    final_value, portfolio_history = evaluate_agent(best_agent, data)

    plt.figure(figsize=(12, 6))
    plt.plot(data[3:], label="Price")
    plt.plot(portfolio_history, label="Agent Portfolio Value")
    plt.title("Best Agent vs Synthetic Crypto Price")
    plt.xlabel("Time Step")
    plt.ylabel("Value")
    plt.legend()
    plt.grid()
    plt.tight_layout()
    plt.show()

if __name__ == '__main__':
    evolve()


===== FILE: exported_code.txt =====



===== FILE: export_code.py =====

import os
from pathlib import Path
print('imports done')
# Export the current project using paths relative to the working directory
PROJECT_ROOT = Path(__file__).resolve().parent
FOLDER_NAME = PROJECT_ROOT.name
OUTPUT_FILE = PROJECT_ROOT / "exported_code.txt"
print(f'Project Root: {FOLDER_NAME}')
# File types to include
INCLUDE_EXTENSIONS = {".py", ".txt", ".env", ".md"}
print('vars done')
def should_include(file: str) -> bool:
    _, ext = os.path.splitext(file)
    return ext in INCLUDE_EXTENSIONS
print('func done')
with open(OUTPUT_FILE, "w", encoding="utf-8") as out:
    for root, _, files in os.walk(PROJECT_ROOT):
        for file in files:
            if should_include(file):
                full_path = os.path.join(root, file)
                rel_path = os.path.relpath(full_path, PROJECT_ROOT)

                out.write(f"\n\n===== FILE: {rel_path} =====\n\n")

                try:
                    with open(full_path, "r", encoding="utf-8") as f:
                        out.write(f.read())
                except Exception as e:
                    out.write(f"⚠️ Could not read file: {e}")

print(f"✅ Export complete: {OUTPUT_FILE}")



===== FILE: mutations.py =====

from Agent import Agent, Neuron, Synapse
import numpy as np
import random
import copy

def mutate_agent(original_agent, mutation_rate, mutation_strength):
    """
    Creates a mutated copy of an agent, allowing for structural changes (adding neurons),
    modifying its parameters, and potentially pruning.
    """
    mutated_agent = copy.deepcopy(original_agent)

    # --- Structural Mutation: Add Neurons ---
    ADD_NEURON_CHANCE = 0.05 
    MAX_NEURONS_TO_ADD = 2 

    if random.random() < ADD_NEURON_CHANCE:
        num_neurons_to_add = random.randint(1, MAX_NEURONS_TO_ADD)
        current_neuron_count = len(mutated_agent.neurons)
        for i in range(num_neurons_to_add):
            new_neuron_name = f"{mutated_agent.name}_n_new{current_neuron_count + i}"
            new_neuron = Neuron(new_neuron_name)
            mutated_agent.neurons.append(new_neuron)
            
            num_new_synapses_for_neuron = random.randint(7, 15) 
            for _ in range(num_new_synapses_for_neuron):
                if len(mutated_agent.neurons) >= 2: 
                    pre, post = random.sample(mutated_agent.neurons, 2)
                    weight = random.uniform(-1, 1)
                    mutated_agent.synapses.append(Synapse(pre, post, weight))
    
    PRUNING_CHANCE = 0.1 
    PRUNING_NEURON_MAX = 1
    PRUNING_SYNAPSE_MAX_PERCENT = 0.05

    MIN_NEURONS = 4 

    if random.random() < PRUNING_CHANCE:
        neurons_to_prune_count = random.randint(0, PRUNING_NEURON_MAX)
        actual_neurons_to_prune = min(neurons_to_prune_count, len(mutated_agent.neurons) - MIN_NEURONS)
        
        if actual_neurons_to_prune > 0:
            non_output_neurons = [n for n in mutated_agent.neurons if n not in mutated_agent.output_neurons]
            
            if len(non_output_neurons) > 0:
                neurons_to_remove = random.sample(non_output_neurons, min(actual_neurons_to_prune, len(non_output_neurons)))
                
                for neuron_to_remove in neurons_to_remove:
                    mutated_agent.neurons.remove(neuron_to_remove)
                    mutated_agent.synapses = [
                        syn for syn in mutated_agent.synapses 
                        if syn.pre != neuron_to_remove and syn.post != neuron_to_remove
                    ]


    if random.random() < PRUNING_CHANCE:
        num_synapses_to_prune = int(len(mutated_agent.synapses) * PRUNING_SYNAPSE_MAX_PERCENT)
        
        if num_synapses_to_prune > 0:
            synapses_to_remove = random.sample(mutated_agent.synapses, min(num_synapses_to_prune, len(mutated_agent.synapses)))
            for syn in synapses_to_remove:
                mutated_agent.synapses.remove(syn)

    for syn in mutated_agent.synapses:
        if random.random() < mutation_rate:
            syn.weight += random.uniform(-mutation_strength, mutation_strength)
            syn.weight = max(min(syn.weight, 1.0), -1.0)

    for neuron in mutated_agent.neurons:
        if random.random() < mutation_rate:
            neuron.threshold_pos += random.uniform(-0.1, 0.1)
            neuron.threshold_neg += random.uniform(-0.1, 0.1)
            neuron.threshold_pos = max(0.01, min(1.0, neuron.threshold_pos))
            neuron.threshold_neg = min(-0.01, max(-1.0, neuron.threshold_neg))

    mutated_agent.name = 'Child' + f"_mut{random.randint(0, 9999)}_NEURONCOUNT{len(mutated_agent.neurons)}"

    return mutated_agent

===== FILE: __init__.py =====

